{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Thresholds for Dropping vs Imputing Missing Data\n",
    "* **Less than 5% Missing**\n",
    "    * Drop the rows or columns\n",
    "\n",
    "* **5% to 20% Missing**\n",
    "    * Impute using averages, medians, or other simple methods.\n",
    "\n",
    "* **More than 20% Missing**\n",
    "    * Advanced Imputation techniques (KNN, regression, or ML-based models) should be considered.\n",
    "\n",
    "* **Above 40% to 50% Missing**\n",
    "    * Evaluate Necessity of Feature.\n",
    "    * If the feature is crucial, try advanced imputation. Otherwise, consider dropping the entire column."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a33d0fd8fdef7ddb"
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-07T17:40:26.944885Z",
     "start_time": "2025-01-07T17:40:26.942274Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('../data/Titanic-Dataset.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T17:40:27.336744Z",
     "start_time": "2025-01-07T17:40:27.333214Z"
    }
   },
   "id": "c16678d108291dea",
   "execution_count": 279
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CleanseData:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "    \n",
    "    def snapshot(self):\n",
    "        \"\"\"\n",
    "        This method is used to provide a snapshot of the first few rows of data\n",
    "        \"\"\"\n",
    "        return self.df.head()\n",
    "    \n",
    "    def describe_data(self):\n",
    "        \"\"\"\n",
    "        This method is used to provide additional information and statistics about the dataset\n",
    "        \"\"\"\n",
    "        return self.df.info(), self.df.describe()\n",
    "    \n",
    "    @staticmethod\n",
    "    def define_categories(null_percentage: float):\n",
    "        \"\"\"\n",
    "        This method is used to classify columns with missing values into various groups based on the percentage of missing values in the column\n",
    "        \"\"\"\n",
    "        if null_percentage < .05:\n",
    "            return \"drop_row\"\n",
    "        elif null_percentage < .2:\n",
    "            return \"impute_median\"\n",
    "        elif null_percentage < .45:\n",
    "            return \"impute_knn\"\n",
    "        else:\n",
    "            return \"drop_column\"\n",
    "        \n",
    "    def drop_row(self, column_name: str, index_list: list):\n",
    "        \"\"\"\n",
    "        This method is used to drop rows from the df when missing column values are less than 5%\n",
    "        \"\"\"\n",
    "        for index in index_list:\n",
    "            self.df.drop(index, inplace=True)\n",
    "            \n",
    "        print(f\" - Dropped {len(index_list)} rows from the '{column_name}' column of the dataframe\\n\")\n",
    "            \n",
    "        return self.df\n",
    "    \n",
    "    def impute_median(self, column_name: str, index_list: list):\n",
    "        \"\"\"\n",
    "        This method is used to fill NaN values with the median of the column when missing column values are less than 20% and greater than 5%\n",
    "        \"\"\"\n",
    "        median_value = self.df[column_name].median()\n",
    "        self.df[column_name] = self.df[column_name].fillna(median_value)\n",
    "        \n",
    "        print(f\" - Filled {len(index_list)} NaN values from column '{column_name}' with median value {median_value}\\n\") \n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def impute_knn(self, column_name: str, index_list: list):\n",
    "        \"\"\"\n",
    "        This method imputes NaN values for specific rows in a column using K-Nearest Neighbors.\n",
    "        \"\"\"\n",
    "        # Extract the relevant column for imputation\n",
    "        temp_df = self.df[[column_name]].copy()\n",
    "    \n",
    "        # Apply KNN Imputer to the entire column\n",
    "        imputer = KNNImputer(n_neighbors=3)\n",
    "        imputed_values = imputer.fit_transform(temp_df)\n",
    "    \n",
    "        # Convert to DataFrame to preserve index\n",
    "        imputed_df = pd.DataFrame(imputed_values, columns=[column_name], index=temp_df.index)\n",
    "    \n",
    "        # Update only the rows specified by index_list\n",
    "        self.df.loc[index_list, column_name] = imputed_df.loc[index_list, column_name]\n",
    "        \n",
    "        print(f\" - Imputed {len(index_list)} NaN values from column '{column_name}' using K-Nearest neighbors algorithm\\n\")\n",
    "    \n",
    "        return self.df\n",
    "    \n",
    "    def drop_column(self, column_name: str, index_list: list):\n",
    "        \"\"\"\n",
    "        This method is used to drop columns from the df when missing column values are greater than 45%\n",
    "        \"\"\"\n",
    "        self.df.drop(columns=[column_name], inplace=True)\n",
    "        \n",
    "        print(f\" - Dropped column '{column_name}' containing {len(index_list)} NaN values\\n\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def handle_null(self):\n",
    "        \"\"\"\n",
    "        This method is used to handle NaN values in the dataframe\n",
    "        \"\"\"\n",
    "        # Drop duplicates\n",
    "        print(f\"DROPPING DUPLICATES...\\n\")\n",
    "        before_drop = len(self.df)\n",
    "        self.df = self.df.drop_duplicates()\n",
    "        after_drop = len(self.df)\n",
    "        print(f\"* Dropped {before_drop - after_drop} duplicate rows from dataframe.\\n\\n\")\n",
    "        \n",
    "        print(f\"BEGINNING TO HANDLE NULL VALUES...\\n\")\n",
    "        non_zero_dict = {}\n",
    "        \n",
    "        na_percentage = (self.df.isnull().sum() / len(self.df))\n",
    "        non_zero_na = na_percentage[na_percentage > 0]\n",
    "        \n",
    "        for index, value in non_zero_na.items():\n",
    "            non_zero_dict[index] = {\n",
    "                \"null_percent\": value,\n",
    "                \"category\": CleanseData.define_categories(value),\n",
    "                \"indexes\": self.df[self.df[index].isnull()].index.tolist()\n",
    "            }\n",
    "            print(f\"* Column '{index}' has {value * 100:.2f}% null values.\\n\")\n",
    "        \n",
    "        for key, value in non_zero_dict.items():\n",
    "            if value['category'] == \"drop_row\":\n",
    "                self.drop_row(column_name=key, index_list=value['indexes'])\n",
    "            elif value['category'] == \"impute_median\":\n",
    "                self.impute_median(column_name=key, index_list=value['indexes'])\n",
    "            elif value['category'] == \"impute_knn\":\n",
    "                self.impute_knn(column_name=key, index_list=value['indexes'])\n",
    "            else:\n",
    "                self.drop_column(column_name=key, index_list=value['indexes'])\n",
    "        \n",
    "    \n",
    "    def get_report(self):\n",
    "        self.handle_null()\n",
    "        return self.df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T17:41:02.534842Z",
     "start_time": "2025-01-07T17:41:02.522325Z"
    }
   },
   "id": "6c31136dfb97fea5",
   "execution_count": 284
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROPPING DUPLICATES...\n",
      "\n",
      "* Dropped 0 duplicate rows from dataframe.\n",
      "\n",
      "\n",
      "BEGINNING TO HANDLE NULL VALUES...\n",
      "\n",
      "* Column 'Age' has 19.87% null values.\n",
      "\n",
      "* Column 'Cabin' has 77.10% null values.\n",
      "\n",
      "* Column 'Embarked' has 0.22% null values.\n",
      "\n",
      " - Filled 177 NaN values from column 'Age' with median value 28.0\n",
      "\n",
      " - Dropped column 'Cabin' containing 687 NaN values\n",
      "\n",
      " - Dropped 2 rows from the 'Embarked' column of the dataframe\n"
     ]
    },
    {
     "data": {
      "text/plain": "     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female  28.0      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Embarked  \n0        0         A/5 21171   7.2500        S  \n1        0          PC 17599  71.2833        C  \n2        0  STON/O2. 3101282   7.9250        S  \n3        0            113803  53.1000        S  \n4        0            373450   8.0500        S  \n..     ...               ...      ...      ...  \n886      0            211536  13.0000        S  \n887      0            112053  30.0000        S  \n888      2        W./C. 6607  23.4500        S  \n889      0            111369  30.0000        C  \n890      0            370376   7.7500        Q  \n\n[889 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>28.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>889 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanser = CleanseData(titanic_df)\n",
    "\n",
    "cleanser.get_report()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-07T17:42:08.490077Z",
     "start_time": "2025-01-07T17:42:08.478907Z"
    }
   },
   "id": "26541e7181d65996",
   "execution_count": 290
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "99416fb3e751772a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
